version: "3.8"

services:

  airflow-webserver:
    image: puckel/docker-airflow:1.10.9
    restart: always
    volumes:
      - ./pricepluscost/etl/dags:/usr/local/airflow/dags
      - ./pricepluscost/etl/plugins:/usr/local/airflow/plugins
      - ./requirements.txt:/requirements.txt
    env_file:
      - .env
      - ./_docker/airflow.cfg.env
    environment:
      - AIRFLOW_CONN_S3CONN=s3://s3/?aws_access_key_id=${S3_ACCESS_KEY_ID},"aws_secret_access_key=${S3_SECRET_ACCESS_KEY}
      - AIRFLOW__CORE__REMOTE_BASE_LOG_FOLDER=s3://${S3_BUCKET}/logs
    ports:
      - "8080:8080"
    command: webserver
    healthcheck:
      test: ["CMD-SHELL", "[ -f /usr/local/airflow/airflow-webserver.pid ]"]
      interval: 30s
      timeout: 30s
      retries: 3

  airflow-scheduler:
    image: puckel/docker-airflow:1.10.9
    restart: always
    depends_on:
      - airflow-webserver
    volumes:
      - ./pricepluscost/etl/dags:/usr/local/airflow/dags
      - ./pricepluscost/etl/plugins:/usr/local/airflow/plugins
      - ./requirements.txt:/requirements.txt
    env_file:
      - .env
      - ./_docker/airflow.cfg.env
    environment:
      - AIRFLOW_CONN_S3CONN=s3://s3/?aws_access_key_id=${S3_ACCESS_KEY_ID},"aws_secret_access_key=${S3_SECRET_ACCESS_KEY}
      - AIRFLOW__CORE__REMOTE_BASE_LOG_FOLDER=s3://${S3_BUCKET}/logs
    command: scheduler

  airflow-worker:
    image: puckel/docker-airflow:1.10.9
    restart: always
    depends_on:
      - airflow-scheduler
    volumes:
      - ./pricepluscost/etl/dags:/usr/local/airflow/dags
      - ./pricepluscost/etl/plugins:/usr/local/airflow/plugins
      - ./requirements.txt:/requirements.txt
    env_file:
      - .env
      - ./_docker/airflow.cfg.env
    environment:
      - AIRFLOW_CONN_S3CONN=s3://s3/?aws_access_key_id=${S3_ACCESS_KEY_ID},"aws_secret_access_key=${S3_SECRET_ACCESS_KEY}
      - AIRFLOW__CORE__REMOTE_BASE_LOG_FOLDER=s3://${S3_BUCKET}/logs
    command: worker